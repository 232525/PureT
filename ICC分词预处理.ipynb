{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Image Chinese Captioning Datasets Pre-Processing__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 将官方validation set的标注json文件，转换为COCO评价所需要的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jieba\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = {}\n",
    "val_data['type'] = \"captions\"\n",
    "val_data['info'] = {\n",
    "    \"contributor\": \"Yiyu Wang\", \n",
    "    \"description\": \"ImageChineseCaptioningEval\",\n",
    "    \"url\": \"ttps://github.com/AIChallenger/AI_Challenger.git\",\n",
    "    \"version\": \"1\",\n",
    "    \"year\": 2021\n",
    "}\n",
    "val_data['licenses'] = [{\"url\": \"https://challenger.ai\"}]\n",
    "val_data['images'] = []\n",
    "val_data['annotations'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:37<00:00, 793.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# 官方提供的标注json文件，需要将其数据重组为如MSCOCO评估json文件的形式\n",
    "# --> 参考 caption_validation_annotations.json\n",
    "# 在该数据集下，预测数据json文件中image_id字段需要使用图像的文件名\n",
    "# --> 参考 test.json\n",
    "val_annotation = './ai_challenger_caption_validation_20170910/caption_validation_annotations_20170910.json'\n",
    "\n",
    "with open(val_annotation, 'r') as f:\n",
    "    tmp_data = json.load(f)\n",
    "    \n",
    "caption_id = 1\n",
    "for _ in tqdm(tmp_data):\n",
    "    file_name = _['image_id']           # file name  ***.jpg\n",
    "    image_id = file_name.split('.')[0]  # image id   ***\n",
    "    captions = _['caption']             # captions x5\n",
    "    images_info = {'file_name': file_name, \"id\": image_id}\n",
    "    val_data['images'].append(images_info)\n",
    "    for caption in captions:\n",
    "        _caption = ' '.join(jieba.cut(caption, cut_all=False))\n",
    "        annotations_info = {\n",
    "            'caption': _caption,\n",
    "            'id': caption_id,\n",
    "            'image_id': image_id\n",
    "        }\n",
    "        # print(image_id, caption_id, _caption)\n",
    "        # val_data['images'].append(images_info)\n",
    "        val_data['annotations'].append(annotations_info)\n",
    "        caption_id += 1\n",
    "        \n",
    "with open('./caption_validation_annotations.json', 'w') as f:\n",
    "    json.dump(val_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 获取词汇表，重新划分数据集，将官方的Train (210000) / Val (30000) --> Train(230000) / Val (5000) / Test (5000)\n",
    "\n",
    "2 同时，生成训练所需要的文件，包括数据集各子集的id文件，词汇表文件，Val/Test的GroundTruth文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding=utf-8\n",
    "import jieba\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    _ = jieba.cut(sent, cut_all=False)\n",
    "    return list(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入文件\n",
    "raw_train_annotation_file = './ai_challenger_caption_train_20170902/caption_train_annotations_20170902.json'\n",
    "raw_val_annotation_file = './ai_challenger_caption_validation_20170910/caption_validation_annotations_20170910.json'\n",
    "\n",
    "# 输出文件\n",
    "misc_gts_file = './ICC_train_gts.pkl'\n",
    "misc_cider_file = './ICC_train_cider.pkl'\n",
    "misc_val5k_ann_file = './ICC_captions_val5k.json'  # 必须包含'type':'captions'字段\n",
    "misc_test5k_ann_file = './ICC_captions_test5k.json'# 必须包含'type':'captions'字段\n",
    "sent_input_file = './ICC_train_input.pkl'\n",
    "sent_target_file = './ICC_train_target.pkl'\n",
    "txt_train_id_file = './ICC_train_image_id.txt'\n",
    "txt_val_id_file = './ICC_val_image_id.txt'\n",
    "txt_test_id_file = './ICC_test_image_id.txt'\n",
    "txt_vocabulary_file = './ICC_vocabulary.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取两个输入文件，进行中文分词，统计词汇表；同时，对数据集进行重新划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取源标注文件\n",
    "raw_train_annotation = None\n",
    "raw_val_annotation   = None\n",
    "with open(raw_train_annotation_file, 'r') as f:\n",
    "    raw_train_annotation = json.load(f)\n",
    "\n",
    "with open(raw_val_annotation_file, 'r') as f:\n",
    "    raw_val_annotation = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 210000/210000 [04:38<00:00, 753.28it/s]\n",
      "100%|██████████| 30000/30000 [00:39<00:00, 760.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 230000 230000\n",
      "Val set: 5000 5000\n",
      "Test set: 5000 5000\n"
     ]
    }
   ],
   "source": [
    "token_counter = {}\n",
    "\n",
    "train_id = []\n",
    "val_id = []\n",
    "test_id = []\n",
    "\n",
    "train_ann = []\n",
    "val_ann = []\n",
    "test_ann = []\n",
    "\n",
    "train_cnt = 0\n",
    "val_cnt = 0\n",
    "test_cnt = 0\n",
    "for i, _ in enumerate(tqdm(raw_train_annotation)):\n",
    "    _id = _['image_id']\n",
    "    _sents = _['caption']\n",
    "    # 对5个参考captions进行分词，并重新组合\n",
    "    __sents = []\n",
    "    for _sent in _sents:\n",
    "        _tokens = tokenize(_sent)  # 词汇表统计\n",
    "        __sents.append(\" \".join(_tokens))\n",
    "        for _token in _tokens:\n",
    "            token_counter[_token] = token_counter.get(_token, 0) + 1\n",
    "    # 统计id信息，以及ann信息\n",
    "    train_id.append(_id)\n",
    "    train_ann.append({'image_id': _id, 'caption': __sents})\n",
    "    train_cnt += 1\n",
    "    \n",
    "# 后10000个样本，划分5000作为val，50000作为test\n",
    "for i, _ in enumerate(tqdm(raw_val_annotation)):\n",
    "    _id = _['image_id']\n",
    "    _sents = _['caption']\n",
    "    # 对5个参考captions进行分词，并重新组合\n",
    "    __sents = []\n",
    "    for _sent in _sents:\n",
    "        _tokens = tokenize(_sent)  # 词汇表统计\n",
    "        __sents.append(\" \".join(_tokens))\n",
    "        for _token in _tokens:\n",
    "            token_counter[_token] = token_counter.get(_token, 0) + 1\n",
    "    # 统计id信息，以及ann信息\n",
    "    if i < 20000:\n",
    "        train_id.append(_id)\n",
    "        train_ann.append({'image_id': _id, 'caption': __sents})\n",
    "        train_cnt += 1\n",
    "    elif i >=20000 and i <25000:\n",
    "        val_id.append(_id)\n",
    "        val_ann.append({'image_id': _id, 'caption': __sents})\n",
    "        val_cnt += 1\n",
    "    else:\n",
    "        test_id.append(_id)\n",
    "        test_ann.append({'image_id': _id, 'caption': __sents})\n",
    "        test_cnt += 1\n",
    "\n",
    "print('Train set:', train_cnt, len(train_id))\n",
    "print('Val set:', val_cnt, len(val_id))\n",
    "print('Test set:', test_cnt, len(test_id))\n",
    "# 按照token出现次数排序\n",
    "ct = sorted([(count,token) for token,count in token_counter.items()], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存train / val / test id以及词汇表到txt文件中\n",
    "index = 1\n",
    "token2index = {}  # 分词词汇 -> index序号 映射\n",
    "final_token = []  # 最终收集到的分词词汇集合\n",
    "bad_tokens = []\n",
    "with open(txt_vocabulary_file, 'w') as f:\n",
    "    for count, token in ct:\n",
    "        if count >= 5:\n",
    "            f.write(str(token) + '\\n')\n",
    "            token2index[str(token)] = index\n",
    "            final_token.append((index, str(token)))\n",
    "            index += 1\n",
    "        else:\n",
    "            bad_tokens.append(token)\n",
    "    f.write(str('UNK') + '\\n')\n",
    "    token2index[str('UNK')] = index\n",
    "    final_token.append((index, str('UNK')))\n",
    "    \n",
    "with open('./coco_bad_token.txt', 'w') as f:\n",
    "    for token in bad_tokens:\n",
    "        f.write(str(token) + '\\n')\n",
    "        \n",
    "with open(txt_train_id_file, 'w') as f:\n",
    "    for _id in train_id:\n",
    "        f.write(str(_id) + '\\n')\n",
    "\n",
    "with open(txt_val_id_file, 'w') as f:\n",
    "    for _id in val_id:\n",
    "        f.write(str(_id) + '\\n')\n",
    "\n",
    "with open(txt_test_id_file, 'w') as f:\n",
    "    for _id in test_id:\n",
    "        f.write(str(_id) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 67431.46it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 118294.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# 保存val / test annotation 到json文件中\n",
    "def info_pre():\n",
    "    data = {}\n",
    "    data['type'] = \"captions\"\n",
    "    data['info'] = {\n",
    "        \"contributor\": \"Yiyu Wang\", \n",
    "        \"description\": \"ImageChineseCaptioningEval\",\n",
    "        \"url\": \"ttps://github.com/AIChallenger/AI_Challenger.git\",\n",
    "        \"version\": \"1\",\n",
    "        \"year\": 2021\n",
    "    }\n",
    "    data['licenses'] = [{\"url\": \"https://challenger.ai\"}]\n",
    "    data['images'] = []\n",
    "    data['annotations'] = []\n",
    "    return data\n",
    "\n",
    "# 共用字段生成\n",
    "val_annotation_data = info_pre()\n",
    "test_annotation_data = info_pre()\n",
    "caption_id = 1\n",
    "for _data in tqdm(test_ann):\n",
    "    _image_id = _data['image_id']   # ***.jpg\n",
    "    _id = _image_id.split('.')[0]   # ***\n",
    "    _captions = _data['caption']\n",
    "    test_annotation_data['images'].append({'file_name': _image_id, 'id': _id})\n",
    "    for _caption in _captions:\n",
    "        test_annotation_data['annotations'].append(\n",
    "            {\n",
    "                'caption': _caption,\n",
    "                'id': caption_id,\n",
    "                'image_id': _id\n",
    "            }\n",
    "        )\n",
    "        caption_id += 1\n",
    "        \n",
    "caption_id = 1\n",
    "for _data in tqdm(val_ann):\n",
    "    _image_id = _data['image_id']   # ***.jpg\n",
    "    _id = _image_id.split('.')[0]   # ***\n",
    "    _captions = _data['caption']\n",
    "    val_annotation_data['images'].append({'file_name': _image_id, 'id': _id})\n",
    "    for _caption in _captions:\n",
    "        val_annotation_data['annotations'].append(\n",
    "            {\n",
    "                'caption': _caption,\n",
    "                'id': caption_id,\n",
    "                'image_id': _id\n",
    "            }\n",
    "        )\n",
    "        caption_id += 1\n",
    "        \n",
    "with open(misc_test5k_ann_file, 'w') as f:\n",
    "    json.dump(test_annotation_data, f)\n",
    "    \n",
    "with open(misc_val5k_ann_file, 'w') as f:\n",
    "    json.dump(val_annotation_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据生成的词汇表（包括UNK，从1计数，0用于<sos>和<eos>），以及train_ann生成训练所需的几个pkl文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230000\n",
      "8257\n",
      "8257\n"
     ]
    }
   ],
   "source": [
    "# 未处理信息: train_ann, token2index, final_token\n",
    "print(len(train_ann))\n",
    "print(len(token2index))\n",
    "print(len(final_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230000/230000 [00:40<00:00, 5659.25it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 需要将caption从str序列转为index序列\n",
    "def str2index(sent, token2index):\n",
    "    result = [token2index[str(token)] if str(token) in token2index else token2index[str('UNK')] for token in sent.split(' ')] # 逐token转换为index\n",
    "    result.append(0)  # 在末尾添加 <eos>\n",
    "    return result\n",
    "\n",
    "def fill_list(_list, fill, length):\n",
    "    _len = len(_list)\n",
    "    if _len > length:\n",
    "        return _list[:length]\n",
    "    else:\n",
    "        _fill = [fill for i in range(length-_len)]\n",
    "        return _list + _fill\n",
    "\n",
    "# ICC_train_gts.pkl\n",
    "# ICC_train_input.pkl\n",
    "# ICC_train_target.pkl\n",
    "ICC_train_gts = []     # list\n",
    "ICC_train_input = {}\n",
    "ICC_train_target = {}\n",
    "\n",
    "for _data in tqdm(train_ann):\n",
    "    _image_id = _data['image_id']\n",
    "    _captions = _data['caption']\n",
    "    _index_list = []\n",
    "    _input = []\n",
    "    _target = []\n",
    "    for i, _caption in enumerate(_captions):\n",
    "        # 将_caption从str序列转换为对应的index序列\n",
    "        # NOTE：里面存在几个图像只有4个caption，即存在caption为 \"\"（空），使用同图像另4个中的一个替代\n",
    "        if len(_caption) == 0:\n",
    "            if i != 0:\n",
    "                _caption = _captions[0]\n",
    "            else:\n",
    "                _caption = _captions[i-1]\n",
    "        _caption_index = str2index(_caption, token2index)\n",
    "        _index_list.append(_caption_index[:20]) # 只保留前20个分词，多余的直接舍弃\n",
    "        # 需要将其扩展到长度为20\n",
    "        _input_index = [0] + _caption_index  # 首部添加 <bos>\n",
    "        _target_index = _caption_index       \n",
    "        _input.append(fill_list(_input_index, 0, 20))\n",
    "        _target.append(fill_list(_target_index, -1, 20))\n",
    "        \n",
    "    ICC_train_gts.append(_index_list)\n",
    "    _id = _image_id.split('.')[0]  # 去除'.jpg'，仅保留图像文件名\n",
    "    ICC_train_input[_id] = np.array(_input)\n",
    "    ICC_train_target[_id] = np.array(_target)\n",
    "   \n",
    "# 保存到文件中\n",
    "with open(misc_gts_file, 'wb') as f:\n",
    "    pickle.dump(ICC_train_gts, f)\n",
    "    \n",
    "with open(sent_input_file, 'wb') as f:\n",
    "    pickle.dump(ICC_train_input, f)\n",
    "    \n",
    "with open(sent_target_file, 'wb') as f:\n",
    "    pickle.dump(ICC_train_target, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 生成CIDEr score cache文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# CIDEr score cache file，用于训练过程中快速计算CIDEr得分，避免训练速度瓶颈\n",
    "# ICC_train_cider.pkl\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "def precook(words, n=4, out=False):\n",
    "    \"\"\"\n",
    "    Takes a string as input and returns an object that can be given to\n",
    "    either cook_refs or cook_test. This is optional: cook_refs and cook_test\n",
    "    can take string arguments as well.\n",
    "    :param s: string : sentence to be converted into ngrams\n",
    "    :param n: int    : number of ngrams for which representation is calculated\n",
    "    :return: term frequency vector for occuring ngrams\n",
    "    \"\"\"\n",
    "    counts = defaultdict(int)\n",
    "    for k in range(1,n+1):\n",
    "        for i in range(len(words)-k+1):\n",
    "            ngram = tuple(words[i:i+k])\n",
    "            counts[ngram] += 1\n",
    "    return counts\n",
    "\n",
    "def cook_refs(refs, n=4): ## lhuang: oracle will call with \"average\"\n",
    "    '''Takes a list of reference sentences for a single segment\n",
    "    and returns an object that encapsulates everything that BLEU\n",
    "    needs to know about them.\n",
    "    :param refs: list of string : reference sentences for some image\n",
    "    :param n: int : number of ngrams for which (ngram) representation is calculated\n",
    "    :return: result (list of dict)\n",
    "    '''\n",
    "    return [precook(ref, n) for ref in refs]\n",
    "\n",
    "def cook_test(test, n=4):\n",
    "    '''Takes a test sentence and returns an object that\n",
    "    encapsulates everything that BLEU needs to know about it.\n",
    "    :param test: list of string : hypothesis sentence for some image\n",
    "    :param n: int : number of ngrams for which (ngram) representation is calculated\n",
    "    :return: result (dict)\n",
    "    '''\n",
    "    return precook(test, n, True)\n",
    "\n",
    "# 读取 ICC_train_target.pkl，生成保存 ICC_train_cider.pkl\n",
    "target_seqs = pickle.load(open(sent_target_file, 'rb'), encoding='bytes')\n",
    "print(type(target_seqs))\n",
    "\n",
    "# 读取 ICC_train_gts.pkl 文件\n",
    "gts = pickle.load(open(misc_gts_file, 'rb'), encoding='bytes')\n",
    "print(type(gts))\n",
    "\n",
    "# 核心操作，统计词频（分词词汇的index，非实际str信息）\n",
    "crefs = []\n",
    "for gt in gts:\n",
    "    crefs.append(cook_refs(gt))\n",
    "\n",
    "document_frequency = defaultdict(float)\n",
    "for refs in crefs:\n",
    "    # refs, k ref captions of one image\n",
    "    for ngram in set([ngram for ref in refs for (ngram,count) in ref.items()]):\n",
    "        document_frequency[ngram] += 1\n",
    "ref_len = np.log(float(len(crefs)))\n",
    "pickle.dump(\n",
    "    {'document_frequency': document_frequency, 'ref_len': ref_len }, \n",
    "    open(misc_cider_file, 'wb')\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用SwinTransformer提取ICC数据集的特征\n",
    "\n",
    "NOTE: 此部分代码为在SwinTransformer项目下运行源码，在notebook中运行需要进行修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造ICC Dataset类，用于实现图像的读取与预处理，方便SwinTransformer进行特征提取\n",
    "# tools/ICC_dataset.py\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from timm.data.transforms import _pil_interp\n",
    "\n",
    "class ICCDataset(Dataset):\n",
    "    def __init__(self, img_folder, json_file, img_size=384):\n",
    "        self.img_folder = img_folder\n",
    "        # 读取json文件，获取图像文件名\n",
    "        with open(json_file, 'r') as f:\n",
    "            json_data = json.load(f)\n",
    "            # test 的 json 文件组织形式和 train / val 不一样，需要分开处理\n",
    "            if 'test' in json_file:\n",
    "                self.image_data = [_['file_name']+'.jpg' for _ in json_data['images']]\n",
    "                self.image_data = list(set(self.image_data))  # 去重\n",
    "            else:\n",
    "                self.image_data = [_['image_id'] for _ in json_data]\n",
    "    \n",
    "        # 构建图像预处理单元\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size), interpolation=_pil_interp('bicubic')),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD)]\n",
    "        )\n",
    "    def __len__(self):\n",
    "        return len(self.image_data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.img_folder, self.image_data[index])\n",
    "        img = cv2.imread(img_path)\n",
    "        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        return self.transform(img), self.image_data[index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210000\n"
     ]
    }
   ],
   "source": [
    "# extract_feats_ICC.py\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from models.swin_transformer import SwinTransformer\n",
    "from tools.ICC_dataset import ICCDataset\n",
    "\n",
    "JSON_PATHS = {\n",
    "    'train': 'ai_challenger_caption_train_20170902/caption_train_annotations_20170902.json',\n",
    "    'val': 'ai_challenger_caption_validation_20170910/caption_validation_annotations_20170910.json',\n",
    "    'test_a': 'ai_challenger_caption_test_a_20180103/caption_test_a_annotations_20180103.json',\n",
    "    'test_b': 'ai_challenger_caption_test_b_20180103/caption_test_b_annotations_20180103.json'\n",
    "}\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='extract feature from Swin')\n",
    "    parser.add_argument('--model', help='model weights', type=str, default='./pre_trained/swin_large_patch4_window12_384_22kto1k.pth')\n",
    "    parser.add_argument('--dataset_folder', help='ICC folder', type=str, default='/home/wangyiyu/wangyiyu_data_ssd6/ImageChineseCaptioning_dataset/AI_Challenger/')\n",
    "    parser.add_argument('--dataset_split', nargs='+', help='train/val/test')\n",
    "    parser.add_argument('--out_folder', help='the storage folder of feature', type=str, default='/home/wangyiyu/wangyiyu_data_ssd6/ImageChineseCaptioning_dataset/AI_Challenger/SwinL_features')\n",
    "    parser.add_argument('--batch_size', help='batch size', type=int, default=1)\n",
    "    parser.add_argument('--num_workers', help='number of workers', type=int, default=1)\n",
    "    \n",
    "    if len(sys.argv) == 1:\n",
    "        parser.print_help()\n",
    "        sys.exit(1)\n",
    "        \n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def forward_feats(model, x):\n",
    "    # 提取图像特征，[B, L, D]\n",
    "    x = model.patch_embed(x)\n",
    "    x = model.pos_drop(x)\n",
    "\n",
    "    for layer in model.layers:\n",
    "        x = layer(x)\n",
    "\n",
    "    x = model.norm(x)  # B L C\n",
    "    return x\n",
    "\n",
    "def extract_feats(model, data_loader, out_folder):\n",
    "    # 输出路径如果不存在，则创建\n",
    "    if not os.path.exists(out_folder):\n",
    "        os.mkdir(out_folder)\n",
    "    \n",
    "    model.eval()\n",
    "    import shutil\n",
    "    for i, (batch_img, img_meta) in enumerate(tqdm(data_loader)):\n",
    "        with torch.no_grad():\n",
    "            feats = forward_feats(model, batch_img.cuda()) # 提取特征\n",
    "          \n",
    "        # 将提取到的特征，转换为numpy.ndarray存储为npz文件\n",
    "        feats_folder = out_folder\n",
    "        for j, img_path in enumerate(img_meta):\n",
    "            img_id = str(img_path.split('.')[0])  # ICC数据集图像文件名即img_id\n",
    "            feat = feats[j]\n",
    "            # print(img_id, feat.cpu().size())\n",
    "            np.savez_compressed(os.path.join(feats_folder, str(img_id)), feat=feat.cpu().numpy())\n",
    "            \n",
    "\n",
    "def main(args):\n",
    "    \n",
    "    batch_size = args.batch_size\n",
    "    num_workers = args.num_workers\n",
    "    # data_folder = '/home/wangyiyu/wangyiyu_data/coco2014/'\n",
    "    data_folder = args.dataset_folder\n",
    "    \n",
    "    split = args.dataset_split\n",
    "    \n",
    "    # 构建模型\n",
    "    model = SwinTransformer(\n",
    "        img_size=384, \n",
    "        embed_dim=192, \n",
    "        depths=[2, 2, 18, 2],\n",
    "        num_heads=[6, 12, 24, 48],\n",
    "        window_size=12,\n",
    "        num_classes=1000\n",
    "    ).cuda()\n",
    "    \n",
    "    # 导入模型参数\n",
    "    # checkpoint_path = './pre_trained/swin_large_patch4_window12_384_22k.pth'\n",
    "    checkpoint_path = args.model\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cuda')\n",
    "    model.load_state_dict(checkpoint['model'], strict=False)\n",
    "    print(model)\n",
    "    \n",
    "    for _ in split:\n",
    "        if _ not in JSON_PATHS:\n",
    "            print('split error, should be train / val / test!')\n",
    "            sys.exit(1)\n",
    "        else:\n",
    "            json_path = JSON_PATHS[_]\n",
    "            # 构造数据集\n",
    "            dataset = ICCDataset(\n",
    "                os.path.join(data_folder, json_path.split('.')[0].replace('annotations', 'images')),\n",
    "                os.path.join(data_folder, json_path)\n",
    "            )\n",
    "            print(_, len(dataset))\n",
    "            dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
    "            \n",
    "            # 提取特征\n",
    "            print('extract feature for %s' % str(_)+'2014')\n",
    "            print('data length:', len(dataset))\n",
    "            extract_feats(model, dataloader, args.out_folder)    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    print(args)\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: 特征提取完成之后发现，train set中存在与test a和test b同名数据（图片分辨率不一致，但属于相同图片），但是标注不完全一致\n",
    "# 与test a同名文件：\n",
    "#   ['4f00cd3c12151a4835394351771c3cead4163504', '7792e3f10ea8cb47d72f00055e6d39626355f1ab', 'ffefb84febc02d7378444b4109067c04e1975121', 'ee03bd82f33765ff8bd3c038df87728deaf80e12', '740ba78c6e7d3e87e4c7db16ec435bfa996af45e', '63bb7d86af30f0bd9c17c1db073f84c870a015c6', 'c35ea7caa03f34d23aeb90c6b38da949d2d65632', 'f8554ea6a881eb48203db4c04daa9bb99f5317e9', 'c780ac6640c9cb66fe5d95d3e06ba202932d6931', '57efb4b95ef0a6098c59b6a4861e676c798d476c', '9bce1bd771b395e6081445197052a9d2487e116c', 'a3b529fbc407beba26e2069fb55757179639a413', 'ee6cbf98ee35d4eb4283dc0b284194b1c27cd20f', 'bd31b5ec946bb9b941008e045f76393a1e715fbb', '60326b2ae46317fd56cb5c3a43a08dcc4cb1b798', '8be62893034f4038ded00343069cf6af1e18622f', '03f9c6bf168661563a1fe63cab001b31c32828d8', '5e3d6d490384ba9279538fb0ce91f595c030be2b', 'd758b1e63d884afbd458046715c414788f3e2c1b', '9df4b1957cd74348e46395974ae32c65459990f9', 'f0c3f9211bc623dfdc7f51e47abb139f828fa2c3', 'f50ab63f0dfdc0c84628b36b1f2b59ca846002f3', 'f108dcc06d6bc03392d4194b55ba9337babf7bc1', '7e0b97ee7cb090325fe2fca2a7b09a8071861a8e', '1aa34363b77795b35e951e5d88ac41c97648459c', 'd3af8a8b1a4402c0d89c577c2d35b334244087e8', '6da45283e31e3c40eb8e29f379a05268eef67ebc', '187cf95a4c3c09ab6aacd7cc50cc9e8cb2488c93', 'd33d8728737850238b4ad2e98917dd2634f789c3', '5fde1b7a53175481f1df1b047657c5191ba93121']\n",
    "# 与test b同名文件：\n",
    "#   ['290ed792c8315b1478603a34ae8a4adc7aa039b2', '8715aadf88f76080c6453ffb57ee38efbf021d08', 'd1ff7d6c3886da19b4d2ece233fe28b0545b7c95', '54612401fac9b89d6a7278a9f3f934159c180451', 'c6aaa1f23dd70f7af8fd391fcd25aaa325a11054', '4d3e523ff9009069f6d12928e7193c251518d9e3', '8caad04e7571672315b37c4a81522f3778330416', 'b89ee384b0b566e8f6ba9e00d48e75ec61c0296c', 'cf5e4d0178ee5445b3b40a0d6ce00ec4d76fab73', '213d1ec8e1439270a862fceeef63c7246a3fc491', 'c899232b0dba94804d9798b15e42f3967c6483ce', 'd4224522164681666cbc67f4afbe372d84914ffb', '2a98c11f9556cffc5c79d301227649d3b8b2da53', '6ae34d3f49544c1a08d30cc0cc659016793be611', '2ffc2009d22bcfddd52191b73d89af7f9c7ea570', 'bf147aa685469bb95ed34a8812d7ba02ffb99b8f', '1012757b58640d862d1ded08bde7dfd0f8f2d5d1', '996df064e684998f3736958c61053144f65284a0', '4ddcd54822a46bfee743454aac33e04448590b17', '702c4ff9c70d3c373ae303062ad9042bb95dceeb', 'f525426d9551a976de68fbc6e0b8f8fdaffb2a62', '1680797d244c279291a08e10fdc570a06e214261', '24b308b395444241d6ab745b23c9cab847874a83', '7e373dad5cf4d019b46895a840c810410dc0eaa5', 'af0746dfef181b4156ab8112f45bbacc4faec2c4', 'b58a3cfbb489667c1a279ac5919d0ea6dabe8537', '149f7db108275c32efa9eb2179515e886f58811d', '93ce9f9d884b413b37ba21f0440ce7dd3ffff092', '7b33f51f11c6f44636562b8a524b23b121e94f34', '605a7185d234aa999f706ac39819d70eb0b0aa02', 'ba2afd60a9f2d02fe9017b19e03f34828eadb9a7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def get_ids(json_file):\n",
    "    json_data = json.load(open(json_file, 'r'))\n",
    "    if 'test' in json_file:\n",
    "        _ids = [_['file_name'] for _ in json_data['images']]\n",
    "        _ids = list(set(_ids))\n",
    "    else:\n",
    "        _ids = [_['image_id'].split('.')[0] for _ in json_data]\n",
    "            \n",
    "    return _ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "test_a_json_file = './ai_challenger_caption_test_a_20180103/caption_test_a_annotations_20180103.json'\n",
    "test_b_json_file = './ai_challenger_caption_test_b_20180103/caption_test_b_annotations_20180103.json'\n",
    "test_a_ids = get_ids(test_a_json_file)\n",
    "test_b_ids = get_ids(test_b_json_file)\n",
    "test_ids = list(set(test_a_ids + test_b_ids))\n",
    "print(len(test_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 1363/60000 [00:00<00:04, 13628.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 3676/60000 [00:00<00:03, 15543.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 7702/60000 [00:00<00:02, 19052.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▊        | 11177/60000 [00:00<00:02, 22038.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 14703/60000 [00:00<00:01, 24831.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 17774/60000 [00:00<00:01, 26342.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 21072/60000 [00:00<00:01, 28033.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 24499/60000 [00:00<00:01, 29649.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 28043/60000 [00:00<00:01, 31177.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 32072/60000 [00:01<00:00, 33445.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 35546/60000 [00:01<00:00, 33097.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 38947/60000 [00:01<00:00, 33061.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 42378/60000 [00:01<00:00, 33424.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 45766/60000 [00:01<00:00, 33417.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 49447/60000 [00:01<00:00, 34365.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 52913/60000 [00:01<00:00, 32449.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 56510/60000 [00:01<00:00, 33429.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 60000/60000 [00:01<00:00, 32490.69it/s]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# 将test a和test b的特征文件（60000条数据）存放到单独的路径下 （test_a_b）\n",
    "input_folder = './SwinL_features/'\n",
    "out_folder = './SwinL_features/test_a_b'\n",
    "if not os.path.exists(out_folder):\n",
    "    os.mkdir(out_folder)\n",
    "    \n",
    "for _id in tqdm(test_ids):\n",
    "    src_npz = os.path.join(input_folder, _id+'.npz')\n",
    "    tar_npz = os.path.join(out_folder, _id+'.npz')\n",
    "    shutil.move(src_npz, tar_npz)\n",
    "    \n",
    "# 将剩余的npz文件（239939条数据）存放到train_val路径下，\n",
    "# 缺少的61张图像的特征数据，重新使用SwinTransformer提取\n",
    "list_dir = os.listdir(input_folder)\n",
    "train_val_npz = []\n",
    "for _ in list_dir:\n",
    "    if '.npz' in _:\n",
    "        train_val_npz.append(_)\n",
    "print(len(train_val_npz))\n",
    "\n",
    "for _npz in train_val_npz:\n",
    "    src_npz = os.path.join(input_folder, _npz)\n",
    "    tar_npz = os.path.join('./SwinL_features/train_val', _npz)\n",
    "    shutil.move(src_npz, tar_npz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存测试集test a和test b的id到txt文件中，读取其json文件获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a_data = json.load(open('./ai_challenger_caption_test_a_20180103/caption_test_a_annotations_20180103.json', 'r'))\n",
    "test_a_ids = [_['file_name']+'.jpg' for _ in test_a_data['images']]\n",
    "test_a_ids = list(set(test_a_ids))\n",
    "\n",
    "test_b_data = json.load(open('./ai_challenger_caption_test_b_20180103/caption_test_b_annotations_20180103.json', 'r'))\n",
    "test_b_ids = [_['file_name']+'.jpg' for _ in test_b_data['images']]\n",
    "test_b_ids = list(set(test_b_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./ICC_test3w_a_image_id.txt', 'w') as f:\n",
    "    for _id in test_a_ids:\n",
    "        f.write(str(_id) + '\\n')\n",
    "        \n",
    "with open('./ICC_test3w_b_image_id.txt', 'w') as f:\n",
    "    for _id in test_b_ids:\n",
    "        f.write(str(_id) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理测试集test a和test b的ground truth文件，将其中的image_id替换为图像的文件名\n",
    "\n",
    "（原本的image_id意义不明）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ann_json(in_file, out_file):\n",
    "    test_data = json.load(open(in_file, 'r'))\n",
    "    id2filename = {}  # 原本的image_id到文件名的映射\n",
    "    filenames = []    # 图像文件名统计\n",
    "    for _ in test_data['images']:\n",
    "        filenames.append(_['file_name']+'.jpg')\n",
    "        if _['id'] not in id2filename:\n",
    "            id2filename[_['id']] = _['file_name']\n",
    "        else:\n",
    "            assert _['file_name'] == id2filename[_['id']], 'Error'\n",
    "\n",
    "    filenames = list(set(filenames))\n",
    "    \n",
    "    # 修改替换'images'字段\n",
    "    test_data['images'] = [{'file_name': filename, 'id': filename.split('.')[0]} for filename in filenames]\n",
    "    # 修改替换'annotations'字段\n",
    "    for _ in test_data['annotations']:\n",
    "        _['image_id'] = id2filename[_['image_id']]\n",
    "\n",
    "    with open(out_file, 'w') as f:\n",
    "        json.dump(test_data, f)\n",
    "\n",
    "process_ann_json(\n",
    "    './ai_challenger_caption_test_a_20180103/caption_test_a_annotations_20180103.json',\n",
    "    './ICC_caption_test_a_annotations_20180103.json'\n",
    ")\n",
    "process_ann_json(\n",
    "    './ai_challenger_caption_test_b_20180103/caption_test_b_annotations_20180103.json',\n",
    "    './ICC_caption_test_b_annotations_20180103.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
